<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of kde</title>
  <meta name="keywords" content="kde">
  <meta name="description" content="KDE: Univariate probability density estimation via kernel method,">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2003-2019 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../index.html">Home</a> &gt;  <a href="index.html">unit</a> &gt; kde.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../index.html"><img alt="<" border="0" src="../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="index.html">Index for unit&nbsp;<img alt=">" border="0" src="../right.png"></a></td></tr></table>-->

<h1>kde
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>KDE: Univariate probability density estimation via kernel method,</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="box"><strong>function hest = kde(histogram,OPT); </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre class="comment">  KDE: Univariate probability density estimation via kernel method,
  ie. kernel density estimation.  That is, given discrete estimates p_k
  of the probability of event x_k (for example, obtained via a
  histgoram), the density estimate f(x) is computed as

  f(x) = 1/(n*v) \sum_{k=1}^n p_k K[ (x-x_k)/v ]

  where K(x) is a smoothing kernel of unit area.

  Usage is

  hest = kde(h,OPT);

  where:
  h:           Data structure specifying discrete estimates p_k of
               events x_k.  It contains elements
  h.p          Vector of estimates p_k;
  h.x          Vector of events x_k.  That is, h.p(k) = p_k = p(x_k).

  OPT:         Data structure which defines options for the estimation
               algorithm as follows:
  OPT.krange:  Width of support of the kernels as an *even* multiplier of
               the width of the bins in the input histogram.  Default is
               OPT.krange=6.
  OPT.knum:    Number of points per bin specified in h.x to be used
               within OPT.krange to represent the kernels.  Default is
               OPT.knum=6;  So, as example, with defaults, if
               elements in h.x are spaced 0.1 units apart, then
               OPT.krange will be 6*0.1=0.6 to span three bins either
               side, and within this range there will be 6 points per
               bin, or 6*6 = 36 points over the 0.6 range used to
               specify the kernels.
  OPT.kernel   A string specifying type of kernel K(x) to be
               used. Options are 'gaussian' and 'triangle'. Default is
               'gaussian';
  OPT.v        Scaling paramter v used to expand or contract K(x) as
               indicated above in specification of kernel density estimate.
               Default is OPT.v = (h.x(2)-h.x(1))^2 - that is, the square
               of the distance between &quot;bins&quot; given in h.x;  
  hest.p       Vector of kernel smoothed probability denisty function
               estimates
  hest.x       Corresponding x axis so that plot(hest.x,hest.p) plots
               estimated probability density function.
  hest.pin     Input probabilities normalised so that with respect to
               h.x, the area underneath the associated input estimate is
               one.  This allows input and output to be compared as
               bar(h.x,hest.pin); hold on; plot(hest.x,hest.p); hold off;

   written by Brett Ninness, School of EE &amp; CS
                             University of Newcastle
                              Australia.</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../matlabicon.gif)">
<li><a href="demo_mcmc.html" class="code" title="">demo_mcmc</a>	</li><li><a href="theta2m.html" class="code" title="function [G,SD] = theta2m(theta,M,fast)">theta2m</a>	THETA2M - function to convert from stacked parameter vector to model</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">%  KDE: Univariate probability density estimation via kernel method,</span>
0002 <span class="comment">%  ie. kernel density estimation.  That is, given discrete estimates p_k</span>
0003 <span class="comment">%  of the probability of event x_k (for example, obtained via a</span>
0004 <span class="comment">%  histgoram), the density estimate f(x) is computed as</span>
0005 <span class="comment">%</span>
0006 <span class="comment">%  f(x) = 1/(n*v) \sum_{k=1}^n p_k K[ (x-x_k)/v ]</span>
0007 <span class="comment">%</span>
0008 <span class="comment">%  where K(x) is a smoothing kernel of unit area.</span>
0009 <span class="comment">%</span>
0010 <span class="comment">%  Usage is</span>
0011 <span class="comment">%</span>
0012 <span class="comment">%  hest = kde(h,OPT);</span>
0013 <span class="comment">%</span>
0014 <span class="comment">%  where:</span>
0015 <span class="comment">%  h:           Data structure specifying discrete estimates p_k of</span>
0016 <span class="comment">%               events x_k.  It contains elements</span>
0017 <span class="comment">%  h.p          Vector of estimates p_k;</span>
0018 <span class="comment">%  h.x          Vector of events x_k.  That is, h.p(k) = p_k = p(x_k).</span>
0019 <span class="comment">%</span>
0020 <span class="comment">%  OPT:         Data structure which defines options for the estimation</span>
0021 <span class="comment">%               algorithm as follows:</span>
0022 <span class="comment">%  OPT.krange:  Width of support of the kernels as an *even* multiplier of</span>
0023 <span class="comment">%               the width of the bins in the input histogram.  Default is</span>
0024 <span class="comment">%               OPT.krange=6.</span>
0025 <span class="comment">%  OPT.knum:    Number of points per bin specified in h.x to be used</span>
0026 <span class="comment">%               within OPT.krange to represent the kernels.  Default is</span>
0027 <span class="comment">%               OPT.knum=6;  So, as example, with defaults, if</span>
0028 <span class="comment">%               elements in h.x are spaced 0.1 units apart, then</span>
0029 <span class="comment">%               OPT.krange will be 6*0.1=0.6 to span three bins either</span>
0030 <span class="comment">%               side, and within this range there will be 6 points per</span>
0031 <span class="comment">%               bin, or 6*6 = 36 points over the 0.6 range used to</span>
0032 <span class="comment">%               specify the kernels.</span>
0033 <span class="comment">%  OPT.kernel   A string specifying type of kernel K(x) to be</span>
0034 <span class="comment">%               used. Options are 'gaussian' and 'triangle'. Default is</span>
0035 <span class="comment">%               'gaussian';</span>
0036 <span class="comment">%  OPT.v        Scaling paramter v used to expand or contract K(x) as</span>
0037 <span class="comment">%               indicated above in specification of kernel density estimate.</span>
0038 <span class="comment">%               Default is OPT.v = (h.x(2)-h.x(1))^2 - that is, the square</span>
0039 <span class="comment">%               of the distance between &quot;bins&quot; given in h.x;</span>
0040 <span class="comment">%  hest.p       Vector of kernel smoothed probability denisty function</span>
0041 <span class="comment">%               estimates</span>
0042 <span class="comment">%  hest.x       Corresponding x axis so that plot(hest.x,hest.p) plots</span>
0043 <span class="comment">%               estimated probability density function.</span>
0044 <span class="comment">%  hest.pin     Input probabilities normalised so that with respect to</span>
0045 <span class="comment">%               h.x, the area underneath the associated input estimate is</span>
0046 <span class="comment">%               one.  This allows input and output to be compared as</span>
0047 <span class="comment">%               bar(h.x,hest.pin); hold on; plot(hest.x,hest.p); hold off;</span>
0048 <span class="comment">%</span>
0049 <span class="comment">%   written by Brett Ninness, School of EE &amp; CS</span>
0050 <span class="comment">%                             University of Newcastle</span>
0051 <span class="comment">%                              Australia.</span>
0052 
0053 <span class="comment">% Copyright (C) Brett Ninness</span>
0054 
0055 <a name="_sub0" href="#_subfunctions" class="code">function hest = kde(histogram,OPT);</a>
0056 
0057 <span class="comment">% For ease of reference shorten name</span>
0058 bin_p = histogram.p; bin_x = histogram.x;
0059 bin_diff = bin_x(2)-bin_x(1);                          <span class="comment">% x axis distance between bins;</span>
0060 
0061 <span class="comment">% Normalise input histogram to have unit area</span>
0062 bin_p=bin_p/(sum(bin_p)*bin_diff);
0063 
0064 <span class="keyword">if</span> ~exist(<span class="string">'OPT'</span>) OPT.krange=6;                    <span class="keyword">end</span>;
0065 <span class="keyword">if</span> ~isfield(OPT,<span class="string">'krange'</span>) OPT.krange=4;           <span class="keyword">end</span>;  <span class="comment">% Width of kernel support as integer multiple of bin_diff - must be even</span>
0066 <span class="keyword">if</span> ~isfield(OPT,<span class="string">'knum'</span>)   OPT.dnum=4*OPT.krange;  <span class="keyword">end</span>;  <span class="comment">% Number of points representing kernel - must be even multipler</span>
0067 <span class="keyword">if</span> ~isfield(OPT,<span class="string">'kernel'</span>) OPT.kernel=<span class="string">'gaussian'</span>;  <span class="keyword">end</span>;  <span class="comment">% Kernel type</span>
0068 <span class="keyword">if</span> ~isfield(OPT,<span class="string">'v'</span>)      OPT.v=(bin_diff^2); <span class="keyword">end</span>;      <span class="comment">% Kernel scaling (variance)</span>
0069 
0070 krange = OPT.krange*bin_diff;                          <span class="comment">% Width of kernel support</span>
0071 del_x = krange/OPT.dnum;                               <span class="comment">% x-axis increment between samples of estimated density</span>
0072 x=-krange/2:del_x:krange/2;                            <span class="comment">% x-axis support of kernel</span>
0073 del_n =  floor(bin_diff/del_x);                        <span class="comment">% Number of x_axis samples between bins of input histogram</span>
0074 lenx = length(x);                                      <span class="comment">% Just to make things more readable below</span>
0075 
0076 <span class="comment">% Compute appropriate kernel</span>
0077 <span class="keyword">if</span> strcmpi(OPT.kernel,<span class="string">'gaussian'</span>)
0078  f = exp(-1/2*(x.^2)/OPT.v)/sqrt(2*pi*OPT.v);
0079 <span class="keyword">elseif</span> strcmpi(OPT.kernel,<span class="string">'triangle'</span>) 
0080  f=max(0,(1/OPT.v-(1/OPT.v^2)*abs(x)));
0081 <span class="keyword">else</span>
0082  error(<span class="string">'Unknown specification for OPT.kernel: type &quot;help kde&quot;'</span>);
0083 <span class="keyword">end</span>;
0084 
0085 <span class="comment">% Now compute smoothed estimate</span>
0086 hest.x = bin_x(1)-krange/2:del_x:bin_x(end)+krange/2;
0087 hest.x = hest.x(1:floor(length(hest.x)/2)*2); <span class="comment">% Make sure of consistency of length (Matlab bug in that sometimes last element not included?)</span>
0088 hest.p = zeros(size(hest.x));  
0089 <span class="keyword">for</span> k=1:length(bin_x)  <span class="comment">% Loop through all bin locations</span>
0090  idx = 1+(k-1)*del_n:lenx+(k-1)*del_n; 
0091  idx = idx(idx&lt;=length(hest.p));  <span class="comment">% If bin_diff is odd then idx could overflow on last frame</span>
0092  hest.p(idx) = hest.p(idx) + bin_p(k)*f(1:length(idx));
0093 <span class="keyword">end</span>;
0094 
0095 <span class="comment">%Output smoothed estimate after normalisation</span>
0096 hest.p=hest.p/(sum(hest.p)*del_x);
0097 
0098 <span class="comment">% Output normalised input</span>
0099 hest.pin = bin_p;
0100 
0101 
0102</pre></div>
<hr><address>Generated on Sun 04-May-2025 22:15:31 by <strong><a href="https://github.com/gllmflndn/m2html">m2html</a></strong> &copy; 2003-2022</address>
</body>
</html>